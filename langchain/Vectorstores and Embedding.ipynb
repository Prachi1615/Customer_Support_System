{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78898c6-d13e-47a7-8848-e010086d668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# # Vectorstores and Embeddings\n",
    "# \n",
    "# Recall the overall workflow for \n",
    "#    Retrieval Augmented Generation (RAG):\n",
    "#\n",
    "# 1. Load documents \n",
    "# 2. Split the documents into small, \n",
    "#    semantically meaningful chunks\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "#    - The index is created by embeddings which are \n",
    "#      numerical representations of text.\n",
    "#    - Text with semantically similar content has similar \n",
    "#      vectors in this numeric space.\n",
    "# 4. Store these index in a vector stores for \n",
    "#    easy retrieval when answering questions\n",
    "# 5. Search answer of a question. \n",
    "#    - Both should have similar index\n",
    "# 6. Edge Cases - Failure\n",
    "#    - 2 types of failures in similarity search\n",
    "#      + Diversity (Example)\n",
    "#      + Specifity (Example)\n",
    "#    - Solved by Advanced Retrieval\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cb1bbe-d2fd-4b7a-8a4b-6ef6c69a70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e422be6b-490a-467c-862c-cbfef241afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "# read the api key from environment variable\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea96953-e22f-4a3d-9082-6144c4a812c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05f738e-cd47-4eb6-9575-f6398c7a2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 1. Load PDF\n",
    "#\n",
    "# References of different loading:\n",
    "# - PDF\n",
    "# - Youtube\n",
    "# - URL\n",
    "# - Notion DB\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d0b618-c39a-44fc-abb0-810ddf3420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\n",
    "      \"2023Catalog.pdf\"),\n",
    "    PyPDFLoader(\n",
    "      \"2023Catalog.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f524a322-7e52-4a9a-a521-85f872383203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 2. Split the content to create chunks\n",
    "#\n",
    "# References\n",
    "# - Document Splitting\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320f8f0b-ffc2-44e5-b2e5-af4a8b7d273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9861b395-e69a-4737-b8c1-4aea6c3563ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054f5838-3315-490e-8ae5-b819d304d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0071c0e3-2b37-4173-a9dc-e77f9e596f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 3. Create an index for each chunk by embeddings\n",
    "# \n",
    "# Let's take our splits and embed them.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f682c7-6611-4f39-92aa-7ec6381a971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7604b2-4039-4d68-81c4-f9b9dff36a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2d3d4c-8d76-4543-b7f5-c59e82cade10",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c02e54a9-b16c-4765-9cc5-46419d1caa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5a98c12-e5b0-434c-8043-9f835d9c647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630350414845891"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy.dot(vector_a, vector_b, out = None) \n",
    "# returns the dot product of vectors a and b.\n",
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf13a114-675a-4b1c-8f64-0ab82eb06bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701147991091326"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f620222-3a7a-4d06-8ee7-0a6fa44c6d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7591130000177128"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5fc91ad-30c3-4b6e-b080-31fa277a1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 4. Vectorstores\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b64660e-19ce-494f-b993-d7761fb7cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/cc/63/b7d76109331318423f9cfb89bd89c99e19f5d0b47a5105439a629224d297/chromadb-0.4.24-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Obtaining dependency information for build>=1.0.3 from https://files.pythonhosted.org/packages/4f/81/4849059526d02fcc9708e19346dd740e8b9edd2f0675ea7c38302d6729df/build-1.1.1-py3-none-any.whl.metadata\n",
      "  Downloading build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (1.10.8)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/11/7a/673ccb9bb2faf9cf655d9040e970c02a96645966e06837fde7d10edf242a/chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Obtaining dependency information for fastapi>=0.95.2 from https://files.pythonhosted.org/packages/f0/f7/ea860cb8aa18e326f411e32ab537424690a53db20de6bad73d70da611fae/fastapi-0.110.0-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/d9/fd/bac111726b6c651f1fa5563145ecba5ff70d36fb140a55e0d79b60b9d65e/uvicorn-0.27.1-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Obtaining dependency information for posthog>=2.4.0 from https://files.pythonhosted.org/packages/6c/5f/24cb22118db0e11703b6b80ef9f982eadde21eb585c3a769719e48dce893/posthog-3.5.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (4.7.1)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/bc/26/e66b500cb1797cc3ae74219d403940e0410b050abc5fda0ea91bcbf61785/pulsar_client-3.4.0-cp311-cp311-macosx_10_15_universal2.whl.metadata\n",
      "  Downloading pulsar_client-3.4.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/89/82/4744bcdefd82e910d530d9f220fd8583d883e2275b6828bc25876051b28c/onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl.metadata\n",
      "  Downloading onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.2 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-api>=1.2.0 from https://files.pythonhosted.org/packages/96/e4/0bfd837c625517dd4c908789a89063247e5769be02b47bf432cde53964e2/opentelemetry_api-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-grpc>=1.2.0 from https://files.pythonhosted.org/packages/67/29/19c639b565c340e25cd7b581e0311a3ccddbeca7906c500f23247f75d321/opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-fastapi>=0.41b0 from https://files.pythonhosted.org/packages/2c/a4/1dde6aa8c6839033e0c4660605ab377c5d75eda31ca067e636843e3a1db9/opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Obtaining dependency information for opentelemetry-sdk>=1.2.0 from https://files.pythonhosted.org/packages/7d/3d/1e991d0badf159dbc090fa4137361ccf77f177c6ee555cf84e3d6ee79b26/opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (0.13.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (4.65.0)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Obtaining dependency information for overrides>=7.3.1 from https://files.pythonhosted.org/packages/2c/ab/fc8290c6a4c722e5514d80f62b2dc4c4df1a68a41d1364e625c35990fcf3/overrides-7.7.0-py3-none-any.whl.metadata\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/ba/0b/27d13042335942abc29a87f49f1ce6b56fa58e025e96454ef25929aeb603/importlib_resources-6.1.2-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Obtaining dependency information for grpcio>=1.58.0 from https://files.pythonhosted.org/packages/d3/8a/4e997c40be25c54b4c46140175052c996a9ca99ae7f563dce29112e5dbcf/grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Downloading grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Obtaining dependency information for bcrypt>=4.0.1 from https://files.pythonhosted.org/packages/a4/72/a1276d2fbf5d1af0e29ff9fb5220ce1d49a5f94ccbfb4f9141c963ff9d0e/bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Obtaining dependency information for typer>=0.9.0 from https://files.pythonhosted.org/packages/bf/0e/c68adf10adda05f28a6ed7b9f4cd7b8e07f641b44af88ba72d9c89e4de7a/typer-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Obtaining dependency information for kubernetes>=28.1.0 from https://files.pythonhosted.org/packages/6f/34/164e57fec8a9693d7e6ae2d1a345482020ea9e9b32eab95a90bb3eaea83d/kubernetes-29.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (6.0)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Obtaining dependency information for mmh3>=4.0.1 from https://files.pythonhosted.org/packages/b3/aa/98511d3ea3f6ba958136d913be3be3c1009be935a20ecc7b2763f0a605b6/mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from chromadb) (3.9.15)\n",
      "Requirement already satisfied: packaging>=19.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Obtaining dependency information for pyproject_hooks from https://files.pythonhosted.org/packages/d5/ea/9ae603de7fbb3df820b23a70f6aff92bf8c7770043254ad8d2dc9d6bcba4/pyproject_hooks-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
      "  Obtaining dependency information for starlette<0.37.0,>=0.36.3 from https://files.pythonhosted.org/packages/eb/f7/372e3953b6e6fbfe0b70a1bb52612eae16e943f4288516480860fcd4ac41/starlette-0.36.3-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for google-auth>=1.0.1 from https://files.pythonhosted.org/packages/b7/1d/f152a5f6d243b6acbb2a710ed19aa47154d678359bed995abdd9daf0cff0/google_auth-2.28.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.28.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for requests-oauthlib from https://files.pythonhosted.org/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for oauthlib>=3.2.2 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for coloredlogs from https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/f3/bf/26deba06a4c910a85f78245cac7698f67cedd7efe00d04f6b3e1b3506a59/protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: sympy in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for deprecated>=1.2.6 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for googleapis-common-protos~=1.52 from https://files.pythonhosted.org/packages/f0/43/c9d8f75ddf08e2a0a27db243c13a700c3cc7ec615b545b697cf6f715ad92/googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-exporter-otlp-proto-common==1.23.0 from https://files.pythonhosted.org/packages/13/ec/b0f12fb97b940ff2977ff77dc913242e2a577179b7f5b276487459a2749e/opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-proto==1.23.0 from https://files.pythonhosted.org/packages/4e/6a/8e5f11827772d1acb27fb2ac33ce12175fb485254de292c8aacd82153bf2/opentelemetry_proto-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation-asgi==0.44b0 from https://files.pythonhosted.org/packages/d0/2f/237518ba94fe56a5b09740e08fddcc4b1cfe5f062d2ec692cca46f810eff/opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-instrumentation==0.44b0 from https://files.pythonhosted.org/packages/bf/e3/b2a8260862d278ac2505c8cb61d11185349f5ea537946220f5c7d738de2a/opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-semantic-conventions==0.44b0 from https://files.pythonhosted.org/packages/ba/0d/3b059755eaaf024261309c3b42fb4d14b2b6e36f58011a63c11817b0a5df/opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for opentelemetry-util-http==0.44b0 from https://files.pythonhosted.org/packages/81/bc/c9073aa85f073093c6f095d9872e12d2c75402cabc9bd87b4e27bfcc7280/opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.0.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Obtaining dependency information for asgiref~=3.0 from https://files.pythonhosted.org/packages/9b/80/b9051a4a07ad231558fcd8ffc89232711b4e618c15cb7a392a17384bbeef/asgiref-3.7.2-py3-none-any.whl.metadata\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Obtaining dependency information for monotonic>=1.5 from https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl.metadata\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/f5/d1/53283b96ed823d5e4d89ee9aa0f29df5a1bdf67f148e061549a595d534e4/httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for uvloop!=0.15.0,!=0.15.1,>=0.14.0 from https://files.pythonhosted.org/packages/41/2a/608ad69f27f51280098abee440c33e921d3ad203e2c86f7262e241e49c99/uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/a3/87/6793ac60d2e20c9c1883aec7431c2e7b501ee44a839f6da1b747c13baa23/watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.5.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for humanfriendly>=9.1 from https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rumnraisin/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.5/528.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.0-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading onnxruntime-1.17.1-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.4.0-cp311-cp311-macosx_10_15_universal2.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.9/145.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.2/418.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=97fe3fb50abbe28e46653899a515d651856b96e2b9bd3f182f85e9c6ab06a8c4\n",
      "  Stored in directory: /Users/rumnraisin/Library/Caches/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, uvloop, uvicorn, typing-extensions, tenacity, rsa, pyproject_hooks, pulsar-client, protobuf, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, importlib-resources, humanfriendly, httptools, grpcio, deprecated, chroma-hnswlib, cachetools, bcrypt, asgiref, watchfiles, typer, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, googleapis-common-protos, google-auth, coloredlogs, build, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.7.2 bcrypt-4.1.2 build-1.1.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 flatbuffers-23.5.26 google-auth-2.28.1 googleapis-common-protos-1.62.0 grpcio-1.62.0 httptools-0.6.1 humanfriendly-10.0 importlib-resources-6.1.2 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 requests-oauthlib-1.3.1 rsa-4.9 starlette-0.36.3 tenacity-8.2.3 typer-0.9.0 typing-extensions-4.10.0 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0\n"
     ]
    }
   ],
   "source": [
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c746481-e428-44a8-a5b8-5ae2e943f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a024b20e-2fd7-42a0-a5bf-c62c17f1dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df5fe8ea-7a65-4535-839a-761204f2333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old database files if any\n",
    "\n",
    "get_ipython().system('rm -rf ./docs/chroma')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f3feced-e0f0-4f62-815d-d12a172aa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "129c338d-042c-4845-b705-9db8a1599a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b0d0906-068d-4de7-b6ed-7c12b2c62c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 5. Similarity Search\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f064f4b1-3607-457d-b403-bfbbe6f46d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45ca5aef-2e21-40ef-8a88-4cd0086bf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "333c73a6-50e9-4563-b3ce-939efca80674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62c2e03b-195f-4d69-ab01-c5bc5e201291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Report Checker  \\n43-4051  43-4051  Customer Service Representatives: Complaint Clerk, Contact Center Specialists, \\nCustomer Complaint Clerk, Customer Contact Specialist, Customer Relations \\nRepresentative, Customer Support Representative, Gas Distribution and Emergency \\nClerk, Passenger Relations Representative, Policyholder I nformation Clerk, Warranty \\nClerk  \\n 43-4199  Information and Record Clerks, All Other: Election Clerk, Flight Crew Scheduler, \\nProbate Clerk, Student Admissions Clerk  \\n 51-1011  First -Line Supervisors of Production and Operating Workers: Assembly Line \\nSupervisor, Printing Supervisor, Printing Worker Supervisor'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6607aeba-5265-43d0-adbf-40606bff0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6474503-4116-4eb0-9ef4-a1d8466b87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6. Edge Case - Failure modes\n",
    "# \n",
    "# This seems great, and basic similarity \n",
    "# search will get you 80% of the way there \n",
    "# very easily. \n",
    "# \n",
    "# But there are some failure modes that can creep up. \n",
    "# \n",
    "# Here are some edge cases that can arise - we'll fix \n",
    "# them in the next class.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f37757e-640a-4421-a677-611bb1ac186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about departments?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f0b11e3-5ecc-4820-b2b5-f7432e1e4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "605895ce-cf5a-41b5-9450-36533e2161d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.1 Edge Case 1 - Failure modes: Diversity\n",
    "# \n",
    "# Notice that we're getting duplicate chunks \n",
    "# (because of the duplicate \n",
    "# `MachineLearning-Lecture01.pdf` in the index).\n",
    "# \n",
    "# Semantic search fetches all similar documents, \n",
    "# but does not enforce diversity.\n",
    "# \n",
    "# `docs[0]` and `docs[1]` are indentical.\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c7cf109-0018-47ba-b53e-676a2842e6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Catalog 202 3 37 ver. 202 3.09.24 the decision, advise the student of his or her right to a hearing, and provide additional information regarding \\nthe hearing.  \\n \\n9. Document Destruction  \\n \\nThe Compliance Department is responsible for the ongoing process of identifying its records, which have \\nmet the required retention period, and overseeing their destruction. Destruction of financial and personnel -\\nrelated documents will be accomplished by sh redding.  \\n \\n10. Legal Hold  \\n \\nFrom time to time, the President may issue a notice, known as a “legal hold,” suspending the destruction of \\nrecords due to pending, threatened, or otherwise reasonably foreseeable litigation, audits, government \\ninvestigations, or similar proceedings. No re cords specified in any legal hold may be destroyed, even if the \\nscheduled destruction date has passed, until the legal hold is withdrawn in writing by the President.  \\n11. Compliance  \\n \\nFailure on the part of employees to follow this policy can result in possible civil and criminal sanctions \\nagainst SFBU  and its employees and possible disciplinary action against responsible individuals. The \\nPresident and the Compliance Department will periodically review these procedures to ensure that they are \\nin compliance with new or revised regulations.  \\n \\n \\n \\nACADEMIC  INTEGRITY POLICY  \\n \\nHonesty and integrity are the virtues that SFBU  holds in high regards. Students are expected to uphold high', metadata={'page': 47, 'source': '2023Catalog.pdf'})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9d71a2b-62c0-4c22-a5c7-7fb4f699fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Catalog 202 3 37 ver. 202 3.09.24 the decision, advise the student of his or her right to a hearing, and provide additional information regarding \\nthe hearing.  \\n \\n9. Document Destruction  \\n \\nThe Compliance Department is responsible for the ongoing process of identifying its records, which have \\nmet the required retention period, and overseeing their destruction. Destruction of financial and personnel -\\nrelated documents will be accomplished by sh redding.  \\n \\n10. Legal Hold  \\n \\nFrom time to time, the President may issue a notice, known as a “legal hold,” suspending the destruction of \\nrecords due to pending, threatened, or otherwise reasonably foreseeable litigation, audits, government \\ninvestigations, or similar proceedings. No re cords specified in any legal hold may be destroyed, even if the \\nscheduled destruction date has passed, until the legal hold is withdrawn in writing by the President.  \\n11. Compliance  \\n \\nFailure on the part of employees to follow this policy can result in possible civil and criminal sanctions \\nagainst SFBU  and its employees and possible disciplinary action against responsible individuals. The \\nPresident and the Compliance Department will periodically review these procedures to ensure that they are \\nin compliance with new or revised regulations.  \\n \\n \\n \\nACADEMIC  INTEGRITY POLICY  \\n \\nHonesty and integrity are the virtues that SFBU  holds in high regards. Students are expected to uphold high', metadata={'page': 47, 'source': '2023Catalog.pdf'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c870e862-1595-47d3-ad59-582018f80b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# 6.2 Edge Case 2 - Failure modes: Specifity\n",
    "#\n",
    "# We can see a new failure mode.\n",
    "# \n",
    "# The question below asks a question about \n",
    "# the third lecture, \n",
    "# but includes results from other lectures \n",
    "# as well.\n",
    "#############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aab35ab8-c6dc-47b6-ba98-bae7e778b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about scholarship \\\n",
    "  for MSEE?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd915140-0ea7-47ed-b5e3-6bf29a1ec84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb93b176-caf3-4bd5-abb9-367273120668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 90, 'source': '2023Catalog.pdf'}\n",
      "{'page': 90, 'source': '2023Catalog.pdf'}\n",
      "{'page': 23, 'source': '2023Catalog.pdf'}\n",
      "{'page': 23, 'source': '2023Catalog.pdf'}\n",
      "{'page': 90, 'source': '2023Catalog.pdf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51ce2f3c-f969-4815-b9c6-2a7dd48694cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Literacy - Demonstrate the expertise and resourcefulness in utilizing multiple sources of \n",
      "information to research and strategize solutions necessary to complete engineering projects.  \n",
      "Integrative Learning, Problem Solving & Creative Thinking - Produce robust hardware/software \n",
      "solutions to meet industry needs in the modern technology areas by utilizing existing technology in a \n",
      "novel manner.  \n",
      " \n",
      "Background Preparation  \n",
      "Students admitted into the MSEE degree program are required to have a bachelor's degree (B S / BA / BE) in \n",
      "electrical or in an other  field with a sufficient background in engineering,  mathematics  and science , including \n",
      "course work and/or experience equivalent  to (as deemed appropriate by the Academic team)  all the following \n",
      "subjects:    \n",
      " \n",
      "1. Mathematics:  Calculus, Linear Algebra,  and Statistics /Probability;   \n",
      "2. Sciences: Physics;  \n",
      "3. Electrical and Computer Engineering Subjects: C Programming, Python Programming , Circuit \n",
      "Theory,  and Logic Design . \n",
      " \n",
      "Additional documents and/or an interview may be requested by the Academic team  to assess and validate the \n",
      "qualification of an applicant who did not complete an undergraduate degree in Electrical Engineering .  \n",
      " \n",
      "A student who lacks any of the background preparation requirements listed above is expected to clear  them \n",
      "by either (1) taking the course at SFBU  or another approved institution/organization that is comparable in\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(docs[4].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9683b8b5-9740-48d7-82d1-043bf4ba1bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lark\n",
      "  Obtaining dependency information for lark from https://files.pythonhosted.org/packages/e7/9c/eef7c591e6dc952f3636cfe0df712c0f9916cedf317810a3bb53ccb65cdd/lark-1.1.9-py3-none-any.whl.metadata\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lark\n",
      "Successfully installed lark-1.1.9\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Retrieval\n",
    "# \n",
    "#  - Retrieval is the centerpiece of our retrieval \n",
    "#    augmented generation (RAG) flow. \n",
    "#    + Let's get our vectorDB from before.\n",
    "#  - Vectorstore Retrieval by Similarity Search\n",
    "#    + Could have 2 types of Edge Failures\n",
    "#      - Diversity\n",
    "#        + Solved by Maximum Marginal Relevance\n",
    "#      - Specifity \n",
    "#        + Solved by working with metadata using\n",
    "#          - Self-Query Retriever\n",
    "#          - Compression\n",
    "# - Traditional approaches which does not use Vectorstore\n",
    "#   + SVM Retrieval\n",
    "#   + TF-IDF Retrieval\n",
    "#############################################################\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Vectorstore retrieval\n",
    "# \n",
    "#############################################################\n",
    "\n",
    "\n",
    "\n",
    "!pip install lark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e8c72ae-f78a-4d10-b214-3c497e870e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Similarity Search\n",
    "#############################################################\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf6d79b9-3eeb-4734-a608-798ca30b6d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is        the Amanita phalloides. Some varieties are        all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of        the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and \\\n",
    "       imposing epigeous (aboveground) fruiting \\\n",
    "       body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is \\\n",
    "       the Amanita phalloides. Some varieties are \\\n",
    "       all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of \\\n",
    "       the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding)\n",
    "\n",
    "question = \"Tell me about all-white mushrooms with \\\n",
    "       large fruiting bodies\"\n",
    "\n",
    "smalldb.similarity_search(question, k=2)\n",
    "\n",
    "\n",
    "smalldb.max_marginal_relevance_search(question,k=2, \n",
    "       fetch_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86c56244-93f2-4fb2-a7d9-c4908eba2b18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning, search, Markov decision processes , constraint satisfaction, graphical models, log'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Addressing Diversity: Maximum marginal relevance\n",
    "# \n",
    "# Last class we introduced one problem: how to enforce \n",
    "# diversity in the search results.\n",
    "#  \n",
    "# `Maximum marginal relevance` strives to achieve \n",
    "# both relevance to the query *and diversity* \n",
    "# among the results.\n",
    "#############################################################\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "docs_ss[0].page_content[:100]\n",
    "\n",
    "docs_ss[1].page_content[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eac0a44-9b24-4ca7-837f-65fedd2a65bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Catalog 202 3 174 ver. 202 3.09.24  \\nPragati Dharmale  \\nM.S.: Master of Science, Information Technol'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Note the difference in results with `MMR`.\n",
    "#############################################################\n",
    "docs_mmr = vectordb.max_marginal_relevance_search(\n",
    "              question,k=3)\n",
    "\n",
    "docs_mmr[0].page_content[:100]\n",
    "\n",
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92d9fe2d-b20b-4e12-b532-8e5db1c4c649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 125, 'source': '2023Catalog.pdf'}\n",
      "{'page': 125, 'source': '2023Catalog.pdf'}\n",
      "{'page': 71, 'source': '2023Catalog.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# ### Addressing Specificity: working with metadata\n",
    "# \n",
    "# In last lecture, we showed that a question about \n",
    "# the third lecture can include results from other \n",
    "# lectures as well.\n",
    "# \n",
    "# To address this, many vectorstores support \n",
    "# operations on `metadata`.\n",
    "# \n",
    "# `metadata` provides context for each embedded chunk.\n",
    "#############################################################\n",
    "\n",
    "\n",
    "question = \"what did they say about CPT \\\n",
    "            in the third trimester?\"\n",
    "\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\n",
    "     \"2023Catalog.pdf\"}\n",
    ")\n",
    "\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90eea14c-a3f2-41ca-9823-559beaa3266a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prerequisite : Open to School of Business Undergraduate Students who have earned 90 trimester units before starting \n",
      "their senior project.  \n",
      " \n",
      " \n",
      "Curricular Practicum  \n",
      " \n",
      "CPT401 Curricular Practicum  (1 unit)  \n",
      "Curricular practicum, or curricular practical training, is a supervised practical experience that is the application of \n",
      "previously studied theory.  The curricular practicum must provide students a valuable learning experience and must \n",
      "significantly increase their knowledge in their program of study . It is defined as alternative work/study, internship, \n",
      "cooperative education, or any other type of required internship or practicum that is offered by sponsoring employers \n",
      "through cooperative agreements with the school and the course is an integral part of an established curriculum.  At \n",
      "least three hours of work in a practical setting has the credit equivalency of one hour of classroom lecture (1 unit).  To \n",
      "be eligible to take this course, the student must have completed at least two  trimester s of coursewor k required in \n",
      "his/her degree program, obtained a written agreement that outlines the arrangement between the institution and the \n",
      "practicum site (including specific learning objectives, course requirements, and evaluation criteria), and received \n",
      "approval by a designated advisor.  F-1 International students must follow additional rules required by the U.S.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba6f21e4-0e23-45ec-b91e-c675d45b6c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Addressing Specificity: working with metadata \n",
    "#                     using Self-Query Retriever\n",
    "# \n",
    "# But we have an interesting challenge: we often \n",
    "# want to infer the metadata from the query itself.\n",
    "# \n",
    "# To address this, we can use `SelfQueryRetriever`, \n",
    "# which uses an LLM to extract:\n",
    "#  \n",
    "# 1. The `query` string to use for vector search\n",
    "# 2. A metadata filter to pass in as well\n",
    "# \n",
    "# Most vector databases support metadata filters, \n",
    "# so this doesn't require any new databases or indexes.\n",
    "############################################################# \n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"source\",\n",
    "   description=\"The lecture the chunk is from, should \\\n",
    "      be one of \\\n",
    "      `2023Catalog.pdf`\",\n",
    "   type=\"string\",\n",
    "   ),\n",
    "\n",
    " AttributeInfo(\n",
    "   name=\"page\",\n",
    "   description=\"The page from the lecture\",\n",
    "   type=\"integer\",\n",
    " ),\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "question = \"what did they say about IEEE?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3dff7e31-0f3e-46a8-8962-5c45efeb69ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 57, 'source': '2023Catalog.pdf'}\n",
      "{'page': 57, 'source': '2023Catalog.pdf'}\n",
      "{'page': 57, 'source': '2023Catalog.pdf'}\n",
      "{'page': 57, 'source': '2023Catalog.pdf'}\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# You will receive a warning about predict_and_parse \n",
    "# being deprecated the first time you executing the \n",
    "# next line. This can be safely ignored.\n",
    "#############################################################\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e2f7e4a-c796-445d-a92a-05085e5ddcac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Additional tricks: compression\n",
    "# \n",
    "# Another approach for improving the quality of \n",
    "# retrieved docs is compression.\n",
    "# \n",
    "# Information most relevant to a query may be \n",
    "# buried in a document with a lot of irrelevant text. \n",
    "# \n",
    "# Passing that full document through your application \n",
    "# can lead to more expensive LLM calls and poorer \n",
    "# responses.\n",
    "# \n",
    "# Contextual compression is meant to fix this. \n",
    "#############################################################\n",
    "\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "  print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" \n",
    "   + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04986f8e-f3f1-4b2b-8475-ae86871ea85f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "F-1 International students  must observe additional rules required by the U.S. Immigration & Customs \n",
      "Enforcement on Curricular Practical Training (CPT).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "F-1 International students  must observe additional rules required by the U.S. Immigration & Customs \n",
      "Enforcement on Curricular Practical Training (CPT).\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Wrap our vectorstore \n",
    "#############################################################\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "\n",
    "question = \"what did they say about CPT?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da5e36b4-9958-4929-a744-33f63357d77e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- \"machine learning, search, Markov decision processes, constraint satisfaction, graphical models, logic, and optimize\"\n",
      "- \"design system by plotting data process curves and error analysis in the model\"\n",
      "- \"Prerequisite: CS250L\"\n",
      "- \"CS485G JavaScript and Internet Programming (3 units)\"\n",
      "- \"This course is designed to provide students with advanced programming knowledge and skills for application development on the Internet.\"\n",
      "- \"Students study both client-side and server-side scripting including HTML, JavaScript, and CSS to develop interactive and responsive web sites.\"\n",
      "- \"Other topics covered include jQuery, Bootstrap, Node.js Express Framework, RESTful API, MongoDB (NoSQL) and various JavaScript frameworks such as Angular and React.\"\n",
      "- \"Hands-on exercises are required.\"\n",
      "- \"Prerequisite: CS250\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- Introduction to Python Programming Language and Programming Logic\n",
      "- Data Structures\n",
      "- Additional documents and/or an interview may be requested by the Academic team to assess and validate the qualification of an applicant who did not complete an undergraduate degree in Computer Science/Engineering.\n",
      "- A student who lacks any of the background preparation requirements listed above is expected to clear them by either (1) taking the course at SFBU or another approved institution/organization that is comparable in subject matter, quality, and rigor as SFBU and earning a grade of at least C or higher, or (2) taking and passing a proficiency exam on the subject.\n",
      "- The student must clear background preparation requirements before acceptance to the MSCS program.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "This course is designed to be taken with the course CS2 30 Linux & Shell Scripting . The students gain hands -on \n",
      "experience with Unix/Linux commands, vi editor, Linux utility, Shell scripting/ programming, security issues, and \n",
      "managing long files and customization of user environment.\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "# Combining various techniques\n",
    "#############################################################\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(\n",
    "        search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80da54dc-eea1-4818-9839-f9927b9437fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Other types of retrieval\n",
    "# \n",
    "# Traditional approaches which does not use Vectorstore\n",
    "# It's worth noting that vectordb as not the only \n",
    "#    kind of tool to retrieve documents. \n",
    "# \n",
    "# The `LangChain` retriever abstraction includes \n",
    "#    other ways to retrieve documents, such as \n",
    "#     - TF-IDF \n",
    "#     - SVM\n",
    "#############################################################\n",
    "\n",
    "from langchain_community.retrievers import SVMRetriever\n",
    "from langchain_community.retrievers import TFIDFRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Load PDF\n",
    "#############################################################\n",
    "loader = PyPDFLoader(\n",
    "  \"2023Catalog.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48fa8913-61fd-4abe-9c61-2d935870f622",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rumnraisin/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='to analyze, design, develop, and implement solutions to challenging novel and existing data science problems . \\nPrerequisite:  MATH208  \\n \\nCS483G Fundament als of Artificial Intelligence  (3 units)  \\nThis course covers artificial intelligence applications in problem solving, reasoning, planning, natural language \\nunderstanding, computer vision, autonomous car navigation, machine learning, business intelligence, robot design, \\nand so on. In order to solve  artificial intelligence problems, the major algorithms include machine learning, search, \\nMarkov decision processes, constraint satisfaction, graphical models, and logic. The main goal of the course is to equip \\nstudents with the tools in Python library to tackle a variety of AI problems in the industries . \\nPrerequisite:  CS250  \\n \\nCS483LG Artificial Intel ligence & Machine Learning Lab (1 unit)  \\nStudents will learn python programming in Google colab platform with numpy, pandas, matplotlib, scikit -learn, \\nseaborn, tensorflow models and Keras API to implement algorithms covered in the lecture from different raw dataset \\nsources. And they will have the  chance to build system for several hand -on design projects. In two hours lab session, \\nstudent will be getting familiar with algorithm functions in above libraries to implement different data processes in \\nmachine learning, search, Markov decision processes , constraint satisfaction, graphical models, logic, and optimize')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Split\n",
    "#############################################################\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Retrieve\n",
    "#############################################################\n",
    "\n",
    "#############################################################\n",
    "# SVM Retriever\n",
    "#############################################################\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "\n",
    "#############################################################\n",
    "# TFIDF Retriever\n",
    "#############################################################\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n",
    "\n",
    "#############################################################\n",
    "# Retrieve with SVM Retriever\n",
    "#############################################################\n",
    "question = \"What are major topics for genAI class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c818a0f9-d6bf-4a96-9aa2-f0d6ea0ba014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"• Bulletin Requirements  \\n \\nThe SFBU  catalog serves as the school's contract with the students.  Therefore, students fall under the \\ngraduation requirements written in the catalog used at the time of the student’s entrance to the program as a \\ndegree  or academic certificate  seeking student.  The section on “Study Plan” in “Academic Information” \\ndescribes the rules for the student to follow for the graduation requirements.  \\n \\n• Petition to Graduate   \\n \\nAs a student approaches the end of his/her undergraduate/graduate study, he/she must initiate a review \\nprocess for the Records Officers to verify the student’s eligibility for graduation.  The student must file an \\nonline petition  form  one trimester  in advance  - prior to his/her last registration – by using the MySFBU  \\nstudent portal  to submit this request.  The Records Office staff will then make a graduation evaluation in time \\nfor the petitioner to register for the last time before graduation.  The student will receive his/her evaluation \\nreport to confirm the courses left for him/her to complete in order to meet his/her graduation requirements.  \\nA graduation fee is charged for each graduation petition .   \\n \\n• Re-petition to Graduate  \\n \\nA student is required to resubmit the request and pay a re -petition fee after filing the original graduation \\nrequest if any of the following occurs:  \\n1. If the petition  for graduation is denied.\")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################################\n",
    "# Retrieve with TFIDF Retriever\n",
    "#############################################################\n",
    "question = \"what did they say about graduation?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a79be7-51be-40ae-b675-b22db4bd3aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
